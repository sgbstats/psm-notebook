---
title: "PSM Notebook"
format: html
author: "Seb Bate"
bibliography: PSM.bib
csl: csl/jama.csl
---

# Pattern Submodels

This is my notebook for all things pattern submodels.

PSM is an under developed method of creating an ensemble of models, one for each of the missing data patterns @fletcher_mercaldo_missing_2020.

## Background

In most clinical prediction models, missing data is either ignored or mean imputed @nijman_missing_2022 @tsvetanova_missing_2021

Using complete-case analysis is only valid when the data is MCAR @rubin1976 @little2019. This leads to the problem of trying to create a CPM when the data is most likely MAR.

## Rationale

The aim is for their to be a prediction model that can be used in general practice and not all parameters are available at all times, especially blood tests. In Bate's review @bate2024, it is noted that several covid prediction models use parameters that are not always available and this means that more often than not, the model can't be used (the review that was in the context of ICU and set in a University Hospital).

## Studies

In ICS-Recode @bate_predictors_2025, clinical data is taken from across studies, with various degrees of missingness. Given that all of the data that is included in the development data are from clinical trials, there data is on the whole very complete. See [studies list](studies.qmd)

## How do pattern submodels work?

Within a models there are 2\^p missingness patterns, every combination of missing and not. Obviously not all patterns are present within the data. For each pattern of data, a model is fitted using only the data that has that pattern (apart from when there are insufficient data, when a complete case models).

Currently it is believed that the psm can handle MAR data because the pattern can take in information from the missingness.

The benefit of these models is that in the wild, there may be reasonable and sensible amounts of missing data and it is useful for the model to be able to handle these users with incomplete data without having to revert to mean/mode imputation.

You can add further requirements, like having mandatory variables to reduce the build time.

## What are the current concerns?

-   Regularisation/shrinkage is a major concern
-   So I don't think that it will be possible to extend this method to the 'data driven' throw everything at the wall and see what sticks method as the parent PSM (aka the complete model) would need to have enough obs that it could then meanifully contribute to the child sub-models where they have insuficient data. Overall one would need `threshold*predictors` number of fully complete cases. 
-   My (maybe naive) understanding for LASSO/Ridge/Elastic net is that as N increases the penalisation is lower (all things being equal). For example, a LASSO may even reduce some params to 0 but then those data are not carried through to the child model that carries the equivalent parameter.
  - LASSO may be workable on complete-case models and any model that has a parameter set to zero gets binned. 
  - I think all of this would apply to Ridge/EN too as the net may unfairly shrink some of the parameters due to low data. 

### To do list

-   Document all of the code so far

-   Discuss issues with model selection and shrinkage

### One day

-   I will make this into a proper R package

### References

::: {#refs}
:::
