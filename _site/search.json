[
  {
    "objectID": "todolist.html",
    "href": "todolist.html",
    "title": "Random to do list",
    "section": "",
    "text": "Remove the %notin% from all of my code\nBuild the Pattern Regression Imputation",
    "crumbs": [
      "To-do list"
    ]
  },
  {
    "objectID": "studies.html",
    "href": "studies.html",
    "title": "Studies",
    "section": "",
    "text": "Short Name\nNCT number\nRelevant Size\n\n\nAnzueto1\nNCT00115492\n797\n\n\nCalverley2\nNCT00476099\n1465\n\n\nDransfield 13\nNCT01009463\n1622\n\n\nDransfield 23\nNCT01017952\n1633\n\n\nEFFECT4\nEudraCT 2012–004162–17\n1765\n\n\nFerguson5\nNCT00144911\n782\n\n\nFLTA30256\n \n640\n\n\nFORWARD7\nNCT00929851\n1186\n\n\nHanania8\n \n723\n\n\nIMPACT9\nNCT02164513\n6221\n\n\nINSTEAD10\nNCT01555138\n581\n\n\nKardos11\n \n994\n\n\nKerwin12\nNCT01053988\n1030\n\n\nMahler13\nNCT00356642\n691\n\n\nMartinez14\nNCT01054885\n1224\n\n\nOhar15\nNCT01110200\n639\n\n\nRISE16\nNCT02157935\n1219\n\n\nSharafkhaneh17\nNCT00419744\n1219\n\n\nSiler18\nNCT02105974\n1622\n\n\nSUMIRE19\nNCT01069289\n1293\n\n\nSUMMIT20\nNCT01313676\n16590\n\n\nSUNSET21\nNCT02603393\n1053\n\n\nTORCH22\nNCT00268216\n6112\n\n\nTRIBUTE23\nNCT02579850\n1532\n\n\nTRISTAN24\n \n1465\n\n\nWISDOM25\nNCT00975195\n2488\n\n\n\n\nReferences\n\n\n1. Anzueto A, Ferguson GT, Feldman G, et al. Effect of fluticasone propionate/salmeterol (250/50) on COPD exacerbations and impact on patient outcomes. COPD: Journal of Chronic Obstructive Pulmonary Disease. 2009;6(5):320-329. doi:10.1080/15412550903140881\n\n\n2. Calverley PMA, Kuna P, Monsó E, et al. Beclomethasone/formoterol in the management of COPD: A randomised controlled trial. Respiratory Medicine. 2010;104(12):1858-1868. doi:10.1016/j.rmed.2010.09.008\n\n\n3. Dransfield MT, Bourbeau J, Jones PW, et al. Once-daily inhaled fluticasone furoate and vilanterol versus vilanterol only for prevention of exacerbations of COPD: Two replicate double-blind, parallel-group, randomised controlled trials. The Lancet Respiratory Medicine. 2013;1(3):210-223. doi:10.1016/S2213-2600(13)70040-7\n\n\n4. Papi A, Dokic D, Tzimas W, et al. Fluticasone propionate/formoterol for COPD management: A randomized controlled trial. International Journal of Chronic Obstructive Pulmonary Disease. 2017;12:1961-1971. doi:10.2147/COPD.S136527\n\n\n5. Ferguson GT, Anzueto A, Fei R, Emmett A, Knobil K, Kalberg C. Effect of fluticasone propionate/salmeterol (250/50 μg) or salmeterol (50 μg) on COPD exacerbations. Respiratory Medicine. 2008;102(8):1099-1108. doi:10.1016/j.rmed.2008.04.019\n\n\n6. GSK - a randomized, double-blind, parallel-group, comparative trial of inhaled fluticasone propionate 250mcg twice daily, 500mcg twice daily, and placebo twice daily via the DISKUS® inhaler in subjects with chronic obstructive pulmonary disease (COPD). https://www.gsk-studyregister.com/en/trial-details/?id=FLTA3025\n\n\n7. Wedzicha JA, Singh D, Vestbo J, et al. Extrafine beclomethasone/formoterol in severe COPD patients with history of exacerbations. Respiratory Medicine. 2014;108(8):1153-1162. doi:10.1016/j.rmed.2014.05.013\n\n\n8. Hanania NA, Darken P, Horstman D, et al. The efficacy and safety of fluticasone propionate (250 μg)/salmeterol (50 μg) combined in the diskus inhaler for the treatment of COPD. CHEST. 2003;124(3):834-843. doi:10.1378/chest.124.3.834\n\n\n9. Lipson DA, Barnhart F, Brealey N, et al. Once-daily single-inhaler triple versus dual therapy in patients with COPD. New England Journal of Medicine. 2018;378(18):1671-1680. doi:10.1056/NEJMoa1713901\n\n\n10. Rossi A, Molen T van der, Olmo R del, et al. INSTEAD: a randomised switch trial of indacaterol versus salmeterol/fluticasone in moderate COPD. European Respiratory Journal. 2014;44(6):1548-1556. doi:10.1183/09031936.00126814\n\n\n11. Kardos P, Wencker M, Glaab T, Vogelmeier C. Impact of salmeterol/fluticasone propionate versus salmeterol on exacerbations in severe chronic obstructive pulmonary disease. American Journal of Respiratory and Critical Care Medicine. 2007;175(2):144-149. doi:10.1164/rccm.200602-244OC\n\n\n12. Kerwin EM, Scott-Wilson C, Sanford L, et al. A randomised trial of fluticasone furoate/vilanterol (50/25 μg; 100/25 μg) on lung function in COPD. Respiratory Medicine. 2013;107(4):560-569. doi:10.1016/j.rmed.2012.12.014\n\n\n13. Mahler DA, Wire P, Horstman D, et al. Effectiveness of fluticasone propionate and salmeterol combination delivered via the diskus device in the treatment of chronic obstructive pulmonary disease. American Journal of Respiratory and Critical Care Medicine. 2002;166(8):1084-1091. doi:10.1164/rccm.2112055\n\n\n14. Martinez FJ, Boscia J, Feldman G, et al. Fluticasone furoate/vilanterol (100/25; 200/25 μg) improves lung function in COPD: A randomised trial. Respiratory Medicine. 2013;107(4):550-559. doi:10.1016/j.rmed.2012.12.016\n\n\n15. Ohar JA, Crater GD, Emmett A, et al. Fluticasone propionate/salmeterol 250/50 μg versus salmeterol 50 μg after chronic obstructive pulmonary disease exacerbation. Respiratory Research. 2014;15(1):105. doi:10.1186/s12931-014-0105-2\n\n\n16. Ferguson GT, Tashkin DP, Skärby T, et al. Effect of budesonide/formoterol pressurized metered-dose inhaler on exacerbations versus formoterol in chronic obstructive pulmonary disease: The 6-month, randomized RISE (revealing the impact of symbicort in reducing exacerbations in COPD) study. Respiratory Medicine. 2017;132:31-41. doi:10.1016/j.rmed.2017.09.002\n\n\n17. Sharafkhaneh A, Southard JG, Goldman M, Uryniak T, Martin UJ. Effect of budesonide/formoterol pMDI on COPD exacerbations: A double-blind, randomized study. Respiratory Medicine. 2012;106(2):257-268. doi:10.1016/j.rmed.2011.07.020\n\n\n18. Siler TM, Nagai A, Scott-Wilson CA, Midwinter DA, Crim C. A randomised, phase III trial of once-daily fluticasone furoate/vilanterol 100/25 μg versus once-daily vilanterol 25 μg to evaluate the contribution on lung function of fluticasone furoate in the combination in patients with COPD. Respiratory Medicine. 2017;123:8-17. doi:10.1016/j.rmed.2016.12.001\n\n\n19. Fukuchi Y, Samoro R, Fassakhov R, et al. Budesonide/formoterol via Turbuhaler® versus formoterol via Turbuhaler® in patients with moderate to severe chronic obstructive pulmonary disease: Phase III multinational study results. Respirology. 2013;18(5):866-873. doi:10.1111/resp.12090\n\n\n20. Vestbo J, Waterer G, Leather D, et al. Mortality after admission with pneumonia is higher than after admission with an exacerbation of COPD. Eur Respir J. Published online 2022. doi:10.1183/13993003.02899-2021\n\n\n21. Chapman KR, Hurst JR, Frent SM, et al. Long-term triple therapy de-escalation to indacaterol/glycopyrronium in patients with chronic obstructive pulmonary disease (SUNSET): A randomized, double-blind, triple-dummy clinical trial. American Journal of Respiratory and Critical Care Medicine. 2018;198(3):329-339. doi:10.1164/rccm.201803-0405OC\n\n\n22. Calverley PMA, Anderson JA, Celli B, et al. Salmeterol and fluticasone propionate and survival in chronic obstructive pulmonary disease. New England Journal of Medicine. 2007;356(8):775-789. doi:10.1056/NEJMoa063070\n\n\n23. Papi A, Vestbo J, Fabbri L, et al. Extrafine inhaled triple therapy versus dual bronchodilator therapy in chronic obstructive pulmonary disease (TRIBUTE): A double-blind, parallel group, randomised controlled trial. The Lancet. 2018;391(10125):1076-1084. doi:10.1016/S0140-6736(18)30206-X\n\n\n24. Calverley P, Pauwels R, Vestbo J, et al. Combined salmeterol and fluticasone in the treatment of chronic obstructive pulmonary disease: A randomised controlled trial. The Lancet. 2003;361(9356):449-456. doi:10.1016/S0140-6736(03)12459-2\n\n\n25. Magnussen H, Disse B, Rodriguez-Roisin R, et al. Withdrawal of inhaled glucocorticoids and exacerbations of COPD. New England Journal of Medicine. 2014;371(14):1285-1294. doi:10.1056/NEJMoa1407154",
    "crumbs": [
      "Studies"
    ]
  },
  {
    "objectID": "sandobox.html",
    "href": "sandobox.html",
    "title": "sandbox",
    "section": "",
    "text": "[1] FALSE\n\n\n[1] TRUE\n\n\n  u w\n1 a b\n\n\n  u w\n1 b c\n\n\nhead(mtcars)\n\n\nsource(\"R/test.R\")\n\n\nhead(mtcars)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1"
  },
  {
    "objectID": "rf.html",
    "href": "rf.html",
    "title": "Random Forests",
    "section": "",
    "text": "Random forest needs to have complete data and ones where there it is missing it seems to want to impute with mean impution. I really don’t like this approach. Tang and Ishwaran (2017)\nTakes sqrt(n) of the variables each time and builds a decision tree from those variables and then takes the average from all of the trees (normally 100)\nFor our big, data driven model. We would end up borrowing across studies, which probably isn’t the end of the world. However, the predict function in the RF package doesn’t like incomplete data.\nMajor question about interaction. I think that we would have add an interaction variable into the datasets but then theoretically it should only be in models when both of the arm and eos (eg) were both in the tree.\nlibrary(randomForest)\nlibrary(tidyverse)\n\n\n\nddm=study_data$EFFECT$ddm %&gt;% \n  dplyr::select(usubjid, paramcd, aval) %&gt;% \n  pivot_wider(names_from=paramcd, values_from=aval) %&gt;% \n  dplyr::select(-BACT)\n\nad=study_data$EFFECT$ad %&gt;% \n  dplyr::select(usubjid, arm_ipd, ics_dose, ics_dose_24, trt_dur, age_imp, ics_bl, sex, cat_bl,\n                fev1_bl, fev1percent_bl, fvc_bl, fev1fvc_bl, laba_bl, lama_bl, comorb_tot_bl, eos_bl, \n                eos_pc_bl, reversibility_bl, smoking_bl, exac_bl, gold_grp, gold_stage, exac_modsev_n)\nmodel=\"rate~.\"\nmodel=as.formula(model)\ndata=merge(ad, ddm, by=\"usubjid\") %&gt;%\n  filter(trt_dur&gt;0.5) %&gt;% \n  #dplyr::mutate_at(c(\"exac_bl\", \"fev1_bl\"),~ifelse(sample(c(TRUE, FALSE), size = length(.), replace = TRUE, prob = c(0.8, 0.2)),., NA))%&gt;% \n  mutate(interaction=eos_bl*if_else(arm_ipd==\"ICS\",1,0),\n         rate=exac_modsev_n/trt_dur) %&gt;% \n  drop_na(rate)%&gt;% \n  dplyr::select(-trt_dur, -exac_modsev_n, -usubjid) %&gt;% \n  mutate(across(where(is.logical), as.integer))\n\ndata2=na.roughfix(data)\n\n\ndata$train=as.logical(rbinom(nrow(data),1, 0.8))\n\nrf=randomForest(formula=model, data=data %&gt;% filter(train) %&gt;% dplyr::select(-train), na.action = na.omit)\nvarImpPlot(rf)\n\n\nnewdata=data %&gt;% filter(!train) %&gt;% \n  dplyr::select(-train)%&gt;%\n  na.roughfix()\n\nz=predict(rf, newdata, se.fit=T)\n\npred.out=data.frame(actual=newdata$rate,\n                    pred=z)\n\npred.out %&gt;% lm(actual~pred, data=.) %&gt;% survival::concordance()\n\n\n\nz1=predict(rf, newdata, predict.all = T)\n\n\n\npred=z1$individual%&gt;% as.data.frame() %&gt;%  mutate(rn=row_number()) %&gt;% \n  pivot_longer(cols=-\"rn\", values_to=\"pred\", names_to = \"tree\") %&gt;% \n  summarise(se.fit=sd(pred,na.rm=T), .by=\"rn\") %&gt;% \n  merge(data.frame(pred=z1$aggregate )%&gt;% mutate(rn=row_number()), by=\"rn\")",
    "crumbs": [
      "Random Forests"
    ]
  },
  {
    "objectID": "rf.html#thoughts-about-imputing-data",
    "href": "rf.html#thoughts-about-imputing-data",
    "title": "Random Forests",
    "section": "Thoughts about imputing data",
    "text": "Thoughts about imputing data\n\nna.roughfix, isn’t a great option but may have some useful properties like actually wanting to reduce variance of predictor as a penalty for having high levels of incompleteness\nHow we would deal with missing data in the test set may be more tricky.\n\nI think we could use MICE to make n=20ish copies of the data to be predicted and then averaged over the prediction. Could be computationally intensive though (as then you be making 10k predictions.\nIn practice you could end up having to impute on the client-side which may not be possible\nOr you use mean/mode imputation for new predictions.\n\n\n\n\nTang, Fei, and Hemant Ishwaran. 2017. “Random Forest Missing Data Algorithms.” Statistical Analysis and Data Mining 10 (6): 363–77. https://doi.org/10.1002/sam.11348.",
    "crumbs": [
      "Random Forests"
    ]
  },
  {
    "objectID": "progress.html",
    "href": "progress.html",
    "title": "Progress",
    "section": "",
    "text": "No confirmed\nSub models: working for normal out of the box methods\n\nLASSO version in development, very slow and currently without a prediction model.\n\nLASSO for big model including interactions working\nRandom forests working",
    "crumbs": [
      "Models progress"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PSM Notebook",
    "section": "",
    "text": "This is my notebook for all things pattern submodels.\nPSM is an under developed method of creating an ensemble of models, one for each of the missing data patterns1.\n\n\nIn most clinical prediction models, missing data is either ignored or mean imputed2 3\nUsing complete-case analysis is only valid when the data is MCAR4 5. This leads to the problem of trying to create a CPM when the data is most likely MAR.\n\n\n\nThe aim is for their to be a prediction model that can be used in general practice and not all parameters are available at all times, especially blood tests. In Bate’s review6, it is noted that several covid prediction models use parameters that are not always available and this means that more often than not, the model can’t be used (the review that was in the context of ICU and set in a University Hospital).\n\n\n\nIn ICS-Recode7, clinical data is taken from across studies, with various degrees of missingness. Given that all of the data that is included in the development data are from clinical trials, there data is on the whole very complete. See studies list\n\n\n\nWithin a models there are 2^p missingness patterns, every combination of missing and not. Obviously not all patterns are present within the data. For each pattern of data, a model is fitted using only the data that has that pattern (apart from when there are insufficient data, when a complete case models).\nCurrently it is believed that the psm can handle MAR data because the pattern can take in information from the missingness.\nThe benefit of these models is that in the wild, there may be reasonable and sensible amounts of missing data and it is useful for the model to be able to handle these users with incomplete data without having to revert to mean/mode imputation.\nYou can add further requirements, like having mandatory variables to reduce the build time.\n\n\n\n\nRegularisation/shrinkage is a major concern\nSo I don’t think that it will be possible to extend this method to the ‘data driven’ throw everything at the wall and see what sticks method as the parent PSM (aka the complete model) would need to have enough obs that it could then meanifully contribute to the child sub-models where they have insuficient data. Overall one would need threshold*predictors number of fully complete cases.\nMy (maybe naive) understanding for LASSO/Ridge/Elastic net is that as N increases the penalisation is lower (all things being equal). For example, a LASSO may even reduce some params to 0 but then those data are not carried through to the child model that carries the equivalent parameter.\nLASSO may be workable on complete-case models and any model that has a parameter set to zero gets binned.\nI think all of this would apply to Ridge/EN too as the net may unfairly shrink some of the parameters due to low data.\n\n\n\n\nDocument all of the code so far\nDiscuss issues with model selection and shrinkage\n\n\n\n\n\nI will make this into a proper R package\n\n\n\n\n\n\n1. Fletcher Mercaldo S, Blume JD. Missing data and prediction: The pattern submodel. Biostatistics. 2020;21(2):236-252. doi:10.1093/biostatistics/kxy040\n\n\n2. Nijman S, Leeuwenberg A, Beekers I, et al. Missing data is poorly handled and reported in prediction model studies using machine learning: A literature review. Journal of Clinical Epidemiology. 2022;142:218-229. doi:10.1016/j.jclinepi.2021.11.023\n\n\n3. Tsvetanova A, Sperrin M, Peek N, Buchan I, Hyland S, Martin GP. Missing data was handled inconsistently in UK prediction models: A review of method used. Journal of Clinical Epidemiology. 2021;140:149-158. doi:10.1016/j.jclinepi.2021.09.008\n\n\n4. Rubin DB. Inference and missing data. Biometrika. 1976;63(3):581-592. doi:10.1093/biomet/63.3.581\n\n\n5. Little RJA, Rubin DB. Statistical Analysis with Missing Data. John Wiley & Sons; 2019.\n\n\n6. Bate S, Stokes V, Greenlee H, et al. External validation of prognostic models in critical care: A cautionary tale from COVID-19 pneumonitis. Critical Care Explorations. 2024;6(4):e1067. doi:10.1097/CCE.0000000000001067\n\n\n7. Bate S, Fortescue R, Fullwood C, et al. Predictors of treatment REsponse to inhaled corticosteroids (ICS) in Chronic Obstructive pulmonary disease: Randomised controlled trials individual participant Data re-Evaluation–protocol of the ICS-RECODE individual participant data meta-analysis. BMJ Open. 2025;15(3):e095541. doi:10.1136/bmjopen-2024-095541",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#background",
    "href": "index.html#background",
    "title": "PSM Notebook",
    "section": "",
    "text": "In most clinical prediction models, missing data is either ignored or mean imputed2 3\nUsing complete-case analysis is only valid when the data is MCAR4 5. This leads to the problem of trying to create a CPM when the data is most likely MAR.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#rationale",
    "href": "index.html#rationale",
    "title": "PSM Notebook",
    "section": "",
    "text": "The aim is for their to be a prediction model that can be used in general practice and not all parameters are available at all times, especially blood tests. In Bate’s review6, it is noted that several covid prediction models use parameters that are not always available and this means that more often than not, the model can’t be used (the review that was in the context of ICU and set in a University Hospital).",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#studies",
    "href": "index.html#studies",
    "title": "PSM Notebook",
    "section": "",
    "text": "In ICS-Recode7, clinical data is taken from across studies, with various degrees of missingness. Given that all of the data that is included in the development data are from clinical trials, there data is on the whole very complete. See studies list",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#how-do-pattern-submodels-work",
    "href": "index.html#how-do-pattern-submodels-work",
    "title": "PSM Notebook",
    "section": "",
    "text": "Within a models there are 2^p missingness patterns, every combination of missing and not. Obviously not all patterns are present within the data. For each pattern of data, a model is fitted using only the data that has that pattern (apart from when there are insufficient data, when a complete case models).\nCurrently it is believed that the psm can handle MAR data because the pattern can take in information from the missingness.\nThe benefit of these models is that in the wild, there may be reasonable and sensible amounts of missing data and it is useful for the model to be able to handle these users with incomplete data without having to revert to mean/mode imputation.\nYou can add further requirements, like having mandatory variables to reduce the build time.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#what-are-the-current-concerns",
    "href": "index.html#what-are-the-current-concerns",
    "title": "PSM Notebook",
    "section": "",
    "text": "Regularisation/shrinkage is a major concern\nSo I don’t think that it will be possible to extend this method to the ‘data driven’ throw everything at the wall and see what sticks method as the parent PSM (aka the complete model) would need to have enough obs that it could then meanifully contribute to the child sub-models where they have insuficient data. Overall one would need threshold*predictors number of fully complete cases.\nMy (maybe naive) understanding for LASSO/Ridge/Elastic net is that as N increases the penalisation is lower (all things being equal). For example, a LASSO may even reduce some params to 0 but then those data are not carried through to the child model that carries the equivalent parameter.\nLASSO may be workable on complete-case models and any model that has a parameter set to zero gets binned.\nI think all of this would apply to Ridge/EN too as the net may unfairly shrink some of the parameters due to low data.\n\n\n\n\nDocument all of the code so far\nDiscuss issues with model selection and shrinkage\n\n\n\n\n\nI will make this into a proper R package\n\n\n\n\n\n\n1. Fletcher Mercaldo S, Blume JD. Missing data and prediction: The pattern submodel. Biostatistics. 2020;21(2):236-252. doi:10.1093/biostatistics/kxy040\n\n\n2. Nijman S, Leeuwenberg A, Beekers I, et al. Missing data is poorly handled and reported in prediction model studies using machine learning: A literature review. Journal of Clinical Epidemiology. 2022;142:218-229. doi:10.1016/j.jclinepi.2021.11.023\n\n\n3. Tsvetanova A, Sperrin M, Peek N, Buchan I, Hyland S, Martin GP. Missing data was handled inconsistently in UK prediction models: A review of method used. Journal of Clinical Epidemiology. 2021;140:149-158. doi:10.1016/j.jclinepi.2021.09.008\n\n\n4. Rubin DB. Inference and missing data. Biometrika. 1976;63(3):581-592. doi:10.1093/biomet/63.3.581\n\n\n5. Little RJA, Rubin DB. Statistical Analysis with Missing Data. John Wiley & Sons; 2019.\n\n\n6. Bate S, Stokes V, Greenlee H, et al. External validation of prognostic models in critical care: A cautionary tale from COVID-19 pneumonitis. Critical Care Explorations. 2024;6(4):e1067. doi:10.1097/CCE.0000000000001067\n\n\n7. Bate S, Fortescue R, Fullwood C, et al. Predictors of treatment REsponse to inhaled corticosteroids (ICS) in Chronic Obstructive pulmonary disease: Randomised controlled trials individual participant Data re-Evaluation–protocol of the ICS-RECODE individual participant data meta-analysis. BMJ Open. 2025;15(3):e095541. doi:10.1136/bmjopen-2024-095541",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "example_studies.html",
    "href": "example_studies.html",
    "title": "Example studies",
    "section": "",
    "text": "EFFECT (data not available)\nMercaldo and Blume data —",
    "crumbs": [
      "Examples studies"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "c4b.html",
    "href": "c4b.html",
    "title": "C for benefit",
    "section": "",
    "text": "In C for benefit, the matching is based on predicted benefit, but what happens when there are substantially different baseline ‘hetrogeneous’ risks? This is based on Klaveren et al. (2018) which used a logistic model.\n\nLit review\nIt appears from Klaveren et al. (2018) that (assuming equal number in each group; in a case of unequal numbers extra people are removed at random), each arm is ranked on predicted treatment benefit. We take \\(rank(\\beta_{het,i})\\) in each arm and rank 1 in treatment is paired with rank 1 in control, two with two etc.\nWhere there is a large homogeneous/baseline effect (that is the outcome is caused in large part by factor(s) that do not interact with treatment), the means that we may end up matching patients with equal/very similar\nEfthimiou et al. (2023) add that C4B can be used by matching on covariates or on the predicted benefit. In a further paper by Hoogland et al. (2024) discuss matching on covariates (via mahlinobis distance) but in high dimensional data, this yields issues. Klaveren et al. (2018) briefly mentioned using MD as a sensitivity analysis but didn’t go into further detail. Smit et al. (2025) used a version called AUC-benefit although the definition was a tad ropey and didn’t use C4B as they didn’t like the matching.\n\n\nModel decomposition\nLet’s consider a model\n\\[\nY \\sim X_1 + X_2 + arm * X_3 + arm * X_4\n\\]\nThis can be rewritten as\n\\[\ny_i= f(\\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{3i} + \\beta_4 x_{4i} + arm_i*(\\beta_a + \\beta_{3a} x_{3i} + \\beta_{4a} x_{4i}), ...)\n\\]\nwhere \\(...\\) is other arguments as required. This can subsequently reduce\n\\[\ny_i=f(\\beta_0+ \\beta_a arm_i+\\beta_{homo,i}+\\beta_{het,i}arm_i,...)\n\\]\n\\[\n\\beta_{homo,i}=\\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{3i} + \\beta_4 x_{4i}\n\\]\n\\[\n\\beta_{het,i}= \\beta_{3a} x_{3i} + \\beta_{4a} x_{4i}\n\\]\nSo in the case where \\(\\beta_a \\gg \\beta_{het,i}\\) and \\(\\beta_{homo,i} \\gg \\beta_{het,i}\\) , this reduces to essentially a homogeneous model and C-for-benefit doesn’t really apply. We will further consider only when \\(\\beta_{het,i}\\) is non-negligible. This does apply to larger and more complex models but we use this model wlog. \\(\\beta_0\\) can be folded into \\(\\beta_{homo,i}\\) and \\(\\beta_{arm}\\) can be folded into \\(\\beta_{het,i}\\) as they shift the values equally for all patients.\nPrevious literature has generally used logistic regression with the ternary outcome (-1,0,1) corresponding to harm, no difference, and benefit respectively. In this analysis we extend the paired outcome to calculated as \\(actual_{trt,j}-actual_{control,j}\\) where j is the \\(j^{th}\\) matched pair. &lt;0 corresponds to harm and &gt;0 corresponds to benefit.\n\n\nMatching procedure\n\nOption 1: Distance between the het and the homo\nAfter reducing the model down to our homo- and hetrogeneous effects, we can match the patients using some distance metric.\nA benefit of this is that the data can be shifted (e.g., folding in the intercept) and that it does not affect the match. The downside of this is that you cannot weight the data.\nWhen calculating C4B you rank the difference in the actual outcome and the rank of the mean hetro value.\n\n\nOption 2: Excess exacerbations\n\nMatching only on the rank of the heterogeneous estimate\nWe calculate the excess exacerbations based on \\(actual_i-\\mathbb{E}(exac_i|arm_i=control)\\)\nIn the case of a pt in the control arm in real life then it would be the difference between predicted and actual\nIn the case of pt in the trt group then the excess captures the treatment effect\nYou then calculate the C4B based on the \\(excess\\sim rank(hetro)\\).\n\nIn this case the hetro values are likely to be a lot closer than when using homo as part of the match.\n\nThis will only work for count or linear models.\n\n\n\nA side note on Random Forests\nIf we were to use the stratified random forests (the proper name I have forgotten), then \\(\\beta_{homo}\\) is the value of the control tree and the \\(\\beta_{het}\\) is the difference in the trees.\n\n\n\nImplementation\n\nlibrary(MASS)\nlibrary(tidyverse)\n\n# Data loaded out of sight\ntrain=data %&gt;% filter(train) %&gt;%  mutate(rate=exac_modsev_n/trt_dur)\ntest=data %&gt;% filter(!train) %&gt;%  mutate(rate=exac_modsev_n/trt_dur)\nformula=rate ~ arm_ipd*eos_bl+age_imp+exac_bl+sex+arm_ipd*smoking_bl+fev1_bl\n\nmodel=glm.nb(formula, train, contrasts=NULL)\n\nsummary(model)\n\n\nCall:\nglm.nb(formula = formula, data = train, contrasts = NULL, init.theta = 0.3624893318, \n    link = log)\n\nCoefficients:\n                              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                   0.025717   0.551433   0.047 0.962803    \narm_ipdICS                   -0.596917   0.206903  -2.885 0.003914 ** \neos_bl                        0.090799   0.478748   0.190 0.849575    \nage_imp                       0.020108   0.006854   2.934 0.003351 ** \nexac_bl                       0.232631   0.065370   3.559 0.000373 ***\nsexM                         -0.284458   0.123649  -2.301 0.021419 *  \nsmoking_blCurrent            -0.092267   0.172938  -0.534 0.593668    \nfev1_bl                      -0.953506   0.171907  -5.547 2.91e-08 ***\narm_ipdICS:eos_bl             0.222578   0.600594   0.371 0.710938    \narm_ipdICS:smoking_blCurrent  0.302984   0.213878   1.417 0.156594    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(0.3625) family taken to be 1)\n\n    Null deviance: 1279.9  on 1415  degrees of freedom\nResidual deviance: 1166.2  on 1406  degrees of freedom\n  (2 observations deleted due to missingness)\nAIC: 4004\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  0.3625 \n          Std. Err.:  0.0236 \n\n 2 x log-likelihood:  -3981.9820 \n\n\nConcordance in train\n\n#finding the rate adjusted concordance\ntrain %&gt;% \n  cbind.data.frame(pred=predict(model, newdata = train, type=\"response\")) %&gt;%\n  mutate(rate=exac_modsev_n/trt_dur,\n         rate_p=pred/trt_dur) %&gt;% \n  lm(rate~rate_p, data=.) %&gt;% \n  survival::concordance()\n\nCall:\nconcordance.lm(object = .)\n\nn= 1416 \nConcordance= 0.6 se= 0.01288\nconcordant discordant     tied.x     tied.y    tied.xy \n    393330     262243          4     346243          0 \n\n\nConcordance in test\n\ntest %&gt;% \n  cbind.data.frame(pred=predict(model, newdata = test, type=\"response\")) %&gt;%\n  mutate(rate=exac_modsev_n/trt_dur,\n         rate_p=pred/trt_dur) %&gt;% \n  lm(rate~rate_p, data=.) %&gt;% \n  survival::concordance()\n\nCall:\nconcordance.lm(object = .)\n\nn= 347 \nConcordance= 0.5595 se= 0.02683\nconcordant discordant     tied.x     tied.y    tied.xy \n     21292      16761          0      21978          0 \n\n\nFWIW this is a weird trial that has almost no ICS effect.\n\nModel decomposition\n\nlibrary(tidyverse)\n\n#' @model a glm to be decomposed\n#' @var the variable to be decomposed over\n#' @newdata any new data to be provided, defaults to null\n#' @leave_as_binary whether to undo the labeliling\n\ndecompose_model &lt;- function(model, var, newdata=NULL, leave_var_as_binary=F) {\n  \n  model_data &lt;- model$model\n  var0=var\n  levels=levels(model_data[[var0]])\n  var=paste0(var0,levels[2])\n  \n  \n  coeffs &lt;- coef(model)\n  \n  if(is.null(newdata)){\n    X &lt;- model.matrix(model)\n  }else{\n    X &lt;- model.matrix(model, data=newdata)\n    model_data=newdata\n  }\n  coeff_names &lt;- names(coeffs)\n  \n  # Identify components\n  homo_terms &lt;- coeff_names[!grepl(paste0(var, \":\"), coeff_names) & coeff_names != var]\n  hetro_terms &lt;- coeff_names[grepl(paste0(var, \":\"), coeff_names)]\n  \n  # Calculate homo component (as before)\n  homo_comp &lt;- X[, homo_terms, drop = FALSE] %*% coeffs[homo_terms]\n  \n  # For hetro component: get the base terms without multiplying by var\n  # Extract the hetro coefficients and multiply by the base variables only\n  hetro_comp &lt;- rep(0, nrow(X))\n  \n  for(term in hetro_terms) {\n    # Get the base variable name (remove \"var:\" prefix)\n    base_var &lt;- gsub(paste0(var, \":\"), \"\", term)\n    # Multiply coefficient by base variable only (not by var)\n    hetro_comp &lt;- hetro_comp + coeffs[term] * X[, base_var]\n  }\n  \n  # Handle var main effect - add it to hetro component\n  if(var %in% coeff_names) {\n    hetro_comp &lt;- hetro_comp + coeffs[var]\n  }\n  \n  # Extract the var data\n  var_data &lt;- X[, var]\n  \n  out=data.frame(\n    homo = as.vector(homo_comp),\n    hetro = as.vector(hetro_comp),\n    var = as.vector(var_data)\n  )\n  colnames(out)[3] &lt;- var0\n  \n  if(!leave_var_as_binary){\n    out[[var0]] &lt;- ifelse(out[[var0]] == 1, levels[2], levels[1])\n  }\n  \n  if(!is.null(attr(model$terms, \"offset\"))){\n    \n    offset_name=(model %&gt;% formula %&gt;% all.vars())[attr(model$terms, \"offset\")]\n    \n    if(is.null(newdata)){\n      offset=model$offset\n    }else{\n      offset=newdata[[offset_name]]\n    }\n    \n    out[[offset_name]]=offset\n  }\n  \n  if(nrow(out)!=nrow(model_data)){stop(\"Row mismatch\")}\n  \n  return(list(\"decomposed_model\"=out, \"data\"=model_data, \"var\"=var0, \"outcome\"=as.character(model$terms)[2]))\n}\n\n\n# Usage\nresult &lt;- decompose_model(model, \"arm_ipd\", leave_var_as_binary = T)\nhead(result$decomposed_model)\n\n         homo      hetro arm_ipd\n1  0.37330801 -0.5524017       1\n2 -0.07046049 -0.2716751       1\n3  0.63597436 -0.2716751       0\n4  0.32601829 -0.5301439       1\n5 -0.20615731 -0.2049017       1\n6  0.00137126 -0.5078861       1\n\n\n\nlibrary(tidyverse)\nlibrary(MatchIt)\n\n#' @dm an output from the decompose model function\n#' @outcome the the outcome variable, passed as a string, defaults to inherit from dm\n#' @var the stratifying variable, also inheritted from dm\n#' @method whether to use 2d of 1d matching\n#' @seeed seed for reproducibility\n#' @link the link function if using 1d match\n\n\nc4b = function(dm, outcome=dm[[\"outcome\"]], var=dm[[\"var\"]], method=c(\"optimal\", \"excess\"), seed=123, link=exp, ...){\n\n  method &lt;- match.arg(method, c(\"optimal\", \"excess\"))\n  \n  result_pre_match &lt;- dm$decomposed_model %&gt;%\n    mutate(rn = row_number()) %&gt;%\n    cbind.data.frame(setNames(list(dm[[\"data\"]][[outcome]]), outcome))\n  \n  set.seed(seed)\n  \n  # Find lower sample size across treatment groups\n  min_size &lt;- result_pre_match %&gt;%\n    group_by(arm_ipd) %&gt;%\n    summarise(n = n()) %&gt;%\n    pull(n) %&gt;%\n    min()\n  \n  # Balance dataset by sampling from the larger group\n  result_balanced &lt;- result_pre_match %&gt;%\n    group_by(arm_ipd) %&gt;%\n    sample_n(min_size, replace = FALSE) %&gt;%\n    ungroup() %&gt;%\n    arrange(rn)\n  \n  # Perform matching depending on method\n  if (method == \"optimal\"){\n    match_formula &lt;- as.formula(paste0(var, \"~ homo + hetro\"))\n    m.out &lt;- matchit(formula = match_formula,\n                     data = result_balanced,\n                     method = \"optimal\",\n                     ratio = 1,\n                     replace = FALSE)\n    \n  } else if (method == \"excess\"){\n\n    result_excess &lt;- result_balanced %&gt;%\n      mutate(excess = .data[[outcome]] - link(homo))\n    \n    match_formula &lt;- as.formula(paste0(var, \"~ hetro\"))\n    m.out &lt;- matchit(arm_ipd ~ hetro,\n                     data = result_excess,\n                     method = \"optimal\",\n                     ratio = 1,\n                     replace = FALSE)\n  }\n  \n  matched_data &lt;- match.data(m.out)\n\n  result_pre_match %&gt;%\n    merge(matched_data %&gt;% dplyr::select(rn, subclass), ., by=\"rn\") %&gt;%\n    mutate(mean_het = mean(hetro), .by=subclass) %&gt;%\n    dplyr::select(all_of(c(outcome)), subclass, mean_het, arm_ipd) %&gt;%\n    pivot_wider(names_from = arm_ipd, values_from = outcome) %&gt;%\n    mutate(diff = `1` - `0`) %&gt;%\n    lm(diff ~ mean_het, data=.) %&gt;%\n    survival::concordance() %&gt;%\n    return()\n}\n\n\nc4b(result, method=\"optimal\")\n\nCall:\nconcordance.lm(object = .)\n\nn= 476 \nConcordance= 0.4791 se= 0.01765\nconcordant discordant     tied.x     tied.y    tied.xy \n     47596      51780        880      12270        524 \n\nc4b(result, method=\"excess\")\n\nCall:\nconcordance.lm(object = .)\n\nn= 476 \nConcordance= 0.4697 se= 0.01737\nconcordant discordant     tied.x     tied.y    tied.xy \n     45611      51655       2383      12316       1085 \n\n\n\nValidation\n\nresult2 &lt;- decompose_model(model, \"arm_ipd\", newdata=test, leave_var_as_binary = T)\nhead(result2$decomposed_model)\n\n         homo      hetro arm_ipd\n1  0.07863149 -0.5969173       1\n2  0.91491513 -0.2049017       1\n3  0.83293578 -0.2716751       1\n4 -0.04367578 -0.1826439       0\n5  0.93619236 -0.4856283       0\n6  0.79518112 -0.2494173       1\n\nc4b(result2, method=\"optimal\")\n\nCall:\nconcordance.lm(object = .)\n\nn= 114 \nConcordance= 0.5496 se= 0.03279\nconcordant discordant     tied.x     tied.y    tied.xy \n      3040       2477        161        722         41 \n\nc4b(result2, method=\"excess\")\n\nCall:\nconcordance.lm(object = .)\n\nn= 114 \nConcordance= 0.5579 se= 0.03565\nconcordant discordant     tied.x     tied.y    tied.xy \n      3109       2455         79        718         80 \n\n\n\n\n\n\n\n\n\nReferences\n\nEfthimiou, Orestis, Jeroen Hoogland, Thomas P. A. Debray, Michael Seo, Toshiaki A. Furukawa, Matthias Egger, and Ian R. White. 2023. “Measuring the Performance of Prediction Models to Personalize Treatment Choice.” Statistics in Medicine 42 (8): 1188–1206. https://doi.org/10.1002/sim.9665.\n\n\nHoogland, J., O. Efthimiou, T. L. Nguyen, and T. P. A. Debray. 2024. “Evaluating Individualized Treatment Effect Predictions: A Model-Based Perspective on Discrimination and Calibration Assessment.” Statistics in Medicine 43 (23): 4481–98. https://doi.org/10.1002/sim.10186.\n\n\nKlaveren, David van, Ewout W. Steyerberg, Patrick W. Serruys, and David M. Kent. 2018. “The Proposed ‘Concordance-Statistic for Benefit’ Provided a Useful Metric When Modeling Heterogeneous Treatment Effects.” Journal of Clinical Epidemiology 94 (February): 59–68. https://doi.org/10.1016/j.jclinepi.2017.10.021.\n\n\nSmit, Jim M., Philip A. Van Der Zee, Sara C. M. Stoof, Michel E. Van Genderen, Dominic Snijders, Wim G. Boersma, Paola Confalonieri, et al. 2025. “Predicting Benefit from Adjuvant Therapy with Corticosteroids in Community-Acquired Pneumonia: A Data-Driven Analysis of Randomised Trials.” The Lancet Respiratory Medicine 13 (3): 221–33. https://doi.org/10.1016/S2213-2600(24)00405-3.",
    "crumbs": [
      "C-for-benefit"
    ]
  },
  {
    "objectID": "helper_functions.html",
    "href": "helper_functions.html",
    "title": "Helper functions",
    "section": "",
    "text": "missingness_pattern\n\nmissingness_pattern=function(SDATA){\n  tmp.dat      &lt;- as.data.frame(is.na(SDATA)*1)\n  tmp.pattern  &lt;- factor(apply(tmp.dat,1,function(z) paste(z,collapse=\"\")))\n  tmp.info     &lt;- split(seq(nrow(SDATA)), tmp.pattern)\n  mp.levels    &lt;- levels(tmp.pattern)\n  mp.pattern   &lt;- do.call(rbind, lapply(as.list(mp.levels),function(ZZ) strsplit(ZZ,'')[[1]]))      \n  mp.info     &lt;- data.frame(cbind(names(tmp.info), unlist(lapply(tmp.info, length))),\n                            stringsAsFactors= FALSE)\n  rownames(mp.info) &lt;- seq(nrow(mp.info))\n  colnames(mp.info) &lt;- c('mp','n')\n  \n  return(list(\"tmp.dat\"=tmp.dat, \"tmp.pattern\"=tmp.pattern, \"tmp.info\"=tmp.info, \"mp.levels\"=mp.levels, \"mp.pattern\"=mp.pattern, \"mp.info\"=mp.info))\n}\n\n\n\nremove_missing_vars\n\nremove_missing_vars=function(model,cols, vars_to_keep){\n  \n  model=as.formula(model) #coerces the model formula into a formula class object\n  unpack(model_breakdown(model))\n  \n  filter_partial_matches=function(vec1, vec2){\n    vec2[sapply(vec2, function(x) any(grepl(paste(vec1, collapse = \"|\"), x)))]\n  }\n  \n  new.mod0=filter_partial_matches(vars_to_keep, mod.rhs)\n  new.mod=paste(mod.lhs,paste(new.mod0,collapse='+'),\n        sep='~')\n  if(length(mod.rhs.interaction)&gt;0){\n    for(i in 1:length(mod.rhs.interaction))\n      new.mod=gsub(gsub(\"\\\\*\",\"\\\\\\\\+\",mod.rhs.interaction[i]),mod.rhs.interaction[i],  new.mod)\n  }\n  return(as.formula(new.mod))\n  \n}\n\n\n\nprint.submodels\n\nsubmodel.print=function(submodels.object, long_wide=c(\"long\", \"wide\"), remove_formula=T){\n  out=list()\n  f &lt;- function(x =c(\"long\", \"wide\")) {\n    x &lt;- match.arg(x)\n    return(x)\n  }\n  out[[\"meta\"]]=submodels.object[[\"meta\"]]\n  coefficients=tidyr::tribble(~\"pattern\",~\"formula\",~\"var\", ~\"coef\" )\n  for(i in 1:(length(submodels.object)-1)){\n    # cat(paste(i, \"\\n\"))\n    coefficients1=data.frame(\"pattern\"=submodels.object[[\"meta\"]][[\"all.patterns\"]][i] %&gt;% as.vector(),\n                             \"formula\"=paste0((submodels.object[[i]][[\"mod\"]][[\"terms\"]] %&gt;% as.character())[2],\n                             (submodels.object[[i]][[\"mod\"]][[\"terms\"]] %&gt;% as.character())[1],\n                               (submodels.object[[i]][[\"mod\"]][[\"terms\"]] %&gt;% as.character())[3]),\n                             \"var\"=names(submodels.object[[i]][[\"mod\"]][[\"coefficients\"]])%&gt;% as.vector(),\n                             \"coef\"=submodels.object[[i]][[\"mod\"]][[\"coefficients\"]])%&gt;% as.vector()\n    row.names(coefficients1)=NULL\n    coefficients=rbind(coefficients, coefficients1)\n    \n  }\n  \n  long_wide=f(long_wide)\n  if(long_wide==\"long\"){\n    out[[\"coefficients\"]]=coefficients\n  }\n  if(long_wide==\"wide\"){\n    out[[\"coefficients\"]]=coefficients %&gt;% pivot_wider(names_from = \"var\", values_from=\"coef\")\n  }\n  \n  if(!remove_formula){\n    out[[\"patterns\"]]=out[[\"coefficients\"]] %&gt;% count(pattern,formula) %&gt;% dplyr::select(-n)\n    \n    \n  }\n  out[[\"coefficients\"]]=out[[\"coefficients\"]] %&gt;% dplyr::select(-\"formula\")\n  \n  return(out)\n}\n\n\n\nmodel_breakdown\n\nmodel_breakdown=function(model){\n  model=as.character(as.formula(model))\n  mod.lhs &lt;- model[2]\n  mod.rhs0 &lt;- model[3]\n  mod.rhs.interaction0 &lt;- strsplit(mod.rhs0,'\\\\+')[[1]]\n  mod.rhs &lt;- strsplit(mod.rhs0,'\\\\+|\\\\*|\\\\:')[[1]] %&gt;% stringr::str_squish()\n  mod.rhs &lt;- stringr::str_squish(mod.rhs[!(mod.rhs%in%c('','+','~'))])\n  \n  #getting the interaction terms\n  mod.rhs.interaction0=mod.rhs.interaction0[which(grepl(\"\\\\*|\\\\:\", mod.rhs.interaction0))]%&gt;% stringr::str_squish()\n  mod.rhs.interaction2=stringr::str_split(mod.rhs.interaction0, \"\\\\*|\\\\:\")\n  mod.rhs.interaction=c()\n  if(length(mod.rhs.interaction2)&gt;0){\n    for(j in 1:length(mod.rhs.interaction2)){\n      for(i in length(mod.rhs.interaction2[[j]]):2){\n        mod.rhs.interaction3=t(combn(mod.rhs.interaction2[[j]],i)) %&gt;% as.data.frame()\n        mod.rhs.interaction4 &lt;- apply( mod.rhs.interaction3 , 1 , paste , collapse = \"*\" )\n        mod.rhs.interaction=c(mod.rhs.interaction, mod.rhs.interaction4)\n        \n      }\n    }\n  }\n  return(list(\"mod.rhs\"=mod.rhs,\n              \"mod.lhs\"=mod.lhs,\n              \"mod.rhs.interaction\"=stringr::str_replace_all(mod.rhs.interaction, pattern = \" \", repl=\"\"),\n              \"mod.rhs.raw\"=mod.rhs0))\n}\n\n\n\nunpack\n\nunpack=function(list, envir= parent.frame())\n{\n  for(i in names(list))\n  {\n    assign(i, list[[i]], envir =envir)\n  }\n}",
    "crumbs": [
      "R Code",
      "Helper Functions"
    ]
  },
  {
    "objectID": "other stuff/abstract.html",
    "href": "other stuff/abstract.html",
    "title": "Abstract",
    "section": "",
    "text": "Missing data is the scourge of prediction models and mishandling of incomplete entries can lead to biased and/or unusable models.\nPattern submodels (PSM) are a method proposed by Fletcher Mercaldo and Blume (2020) which allows a predictive model to be built with datasets with substantial missing data with various missingness mechanisms and without imputation. For each ‘pattern’ of missing data (e.g., FEV1 is missing but all other predictors are present), a model is fitted but only with the data that has this missingness pattern (subject to some other constraints). This leads to 2^p models being fitted (where p is the number of predictors being used). Furthermore, it is easy to make the models interpretable and transportable rather than the ‘blackbox’ of some machine learning techniques.\nCurrently, there has been very little work since that has developed PSMs, despite garnering some interest in their implementation (currently 43 citations in Scopus). While C statistics and calibration curves can be defined for these models, other methods, such as regularisation and shrinkage, to avoid overftting have yet to be developed and so far have caused major questions for these ensemble models. There continues to be questions about how generalisable the models would be if the reasons for missing data are not the same between development and in-the-wild testing.\nAs part of ICS-RECODE, we are using PSMs as a potential approach to handle data missingness within our study datasets. Maybe you could try PSMs for your next prediction model?"
  },
  {
    "objectID": "other stuff/abstract.html#nihr-stats-conference",
    "href": "other stuff/abstract.html#nihr-stats-conference",
    "title": "Abstract",
    "section": "",
    "text": "Missing data is the scourge of prediction models and mishandling of incomplete entries can lead to biased and/or unusable models.\nPattern submodels (PSM) are a method proposed by Fletcher Mercaldo and Blume (2020) which allows a predictive model to be built with datasets with substantial missing data with various missingness mechanisms and without imputation. For each ‘pattern’ of missing data (e.g., FEV1 is missing but all other predictors are present), a model is fitted but only with the data that has this missingness pattern (subject to some other constraints). This leads to 2^p models being fitted (where p is the number of predictors being used). Furthermore, it is easy to make the models interpretable and transportable rather than the ‘blackbox’ of some machine learning techniques.\nCurrently, there has been very little work since that has developed PSMs, despite garnering some interest in their implementation (currently 43 citations in Scopus). While C statistics and calibration curves can be defined for these models, other methods, such as regularisation and shrinkage, to avoid overftting have yet to be developed and so far have caused major questions for these ensemble models. There continues to be questions about how generalisable the models would be if the reasons for missing data are not the same between development and in-the-wild testing.\nAs part of ICS-RECODE, we are using PSMs as a potential approach to handle data missingness within our study datasets. Maybe you could try PSMs for your next prediction model?"
  },
  {
    "objectID": "ri.html",
    "href": "ri.html",
    "title": "Regression Imputation",
    "section": "",
    "text": "Using Sisk1 and further advice, regression imputation allows us to build p deterministic models to impute data. It also gives the ability to impute data on the fly.\nThe basic premise is that you initialise each missing value to the mean (not sure about categorical variables).\nYou then build a model for each variable in turn and use this model to update the missing values from the first variable and then move on to the next variable and repeat. It then loops through all of the variables until it converges (probably 10 times).\nThis gives the opportunity to impute on the fly. You can take the models for imputation and impute any new data (using the same ideas of cycling through until convergence).\nCurrently it is possible to use MICE2 do do a single imputation\nmodel=\"exac_modsev_n ~ arm_ipd*eos_bl+arm_ipd*age_imp+arm_ipd*exac_bl+arm_ipd*sex+arm_ipd*smoking_bl+arm_ipd*fev1_bl+offset(trt_dur)\"\nmodel=as.formula(model)\n\n\ndata=study_data$EFFECT$ad %&gt;% dplyr::mutate_at(c(\"exac_bl\", \"fev1_bl\"),~ifelse(sample(c(TRUE, FALSE), size = length(.), replace = TRUE, prob = c(0.8, 0.2)),., NA)) \ndata$train=as.logical(rbinom(nrow(data),1, 0.8))\n\nunpack(model_breakdown(model))\n\ndata.init=data %&gt;%\n  filter(train) %&gt;% \n  get_all_vars(model, data=.) %&gt;% \n  dplyr::select(-all_of(mod.lhs)) %&gt;% \n  summarise(eos_bl=mean(eos_bl, na.rm=T),\n            arm_ipd=\"ICS\",\n            age_imp=mean(age_imp, na.rm=T),\n            exac_bl=mean(exac_bl, na.rm=T),\n            smoking=\"Former\",\n            fev1_bl=mean(fev1_bl, na.rm=T),\n            trt_dur=mean(trt_dur, na.rm=T),\n            n=n()) %&gt;% \n  uncount(n)\n\nm1=mice::mice(data %&gt;% filter(train) %&gt;% get_all_vars(model, data=.) %&gt;% dplyr::select(-all_of(mod.lhs)), method=\"norm.predict\",data.init=data.init, m=1, maxit=1)\n\n\n iter imp variable\n  1   1  exac_bl  fev1_bl\n\nhead(complete(m1))\n\n  arm_ipd eos_bl age_imp exac_bl sex smoking_bl   fev1_bl    trt_dur\n1     ICS    0.2      55       1   M     Former 0.7600000 0.63244353\n2     ICS    0.1      65       1   M    Current 0.9960195 0.25188227\n3 Control    0.1      75       1   M    Current 0.8000000 0.07118412\n4     ICS    0.3      65       1   M     Former 1.0300000 1.01848049\n5 Control    0.3      65       1   M     Former 0.7400000 0.44626968\n6 Control    0.5      65       1   M    Current 1.2000000 0.63791923\nBut my concern here is that I can’t work out how to run a data-agnostic on the fly imputation so I made my own version.",
    "crumbs": [
      "Regression Imputation"
    ]
  },
  {
    "objectID": "ri.html#home-made-version",
    "href": "ri.html#home-made-version",
    "title": "Regression Imputation",
    "section": "Home made version",
    "text": "Home made version\n\nlibrary(tidyverse)\n\n\nregression_imp=function(data, iter=10, remove_model_data=c(\"model\", \"y\", \"fitted\")){\n  \n  #getting the mean/mode for each column to initialise the data\n  \n  calculate_summary &lt;- function(col) {\n    if (is.numeric(col)) {\n      mean(col, na.rm = TRUE)\n    } else if (is.factor(col)) {\n      mode_val &lt;- levels(col)[which.max(tabulate(col))]\n      factor(mode_val, levels = levels(col))  # preserve factor structure\n    } else {\n      NA\n    }\n  }\n  \n  #initialised data\n  init &lt;- data %&gt;%\n    summarise(across(everything(), calculate_summary))\n  \n  #filling the data in\n  df_filled &lt;- data %&gt;%\n    mutate(across(everything(), ~ coalesce(.x, init[[cur_column()]])))\n  \n  #tracking the missing data\n  na_data=data %&gt;% mutate(across(everything(), ~ ifelse(is.na(.x), 0, 1)))\n  rs=rowSums(na_data)\n  #getting the class of the data\n  class2=function(x)\n  {\n    return(class(x)[1])\n  }\n  t=sapply(df_filled, class2)\n  \n  #build each of the models\n  mod=list()\n  interim=list()\n  #repeat for each iteration\n  for(k in 1:iter){\n    #build a model for each variable\n    for(i in 1:ncol(data)){\n      formula=as.formula(paste0(names(t)[i], \"~.\"))\n      # uses only the known vlaues as the outcome\n      tempdata=df_filled[na_data[i]==1,] %&gt;% droplevels()\n      \n      #currently can only cope with numeric and binary\n      if(t[i]==\"numeric\"){\n        mod[[names(data[i])]]=lm(formula = formula, data=tempdata)\n      }else if(t[i] %in% c(\"factor\", \"logical\")){\n        mod[[names(data[i])]]=glm(formula = formula, data=tempdata, family=\"binomial\")\n      }\n      \n    }\n    \n    \n    for(i in 1:dim(df_filled)[1]){\n      # skips complete rows\n      if(rs[i]==dim(df_filled)[1]){next}\n      for(j in 1:dim(df_filled)[2]){\n        if(na_data[i,j]==1){\n          #skips the known values\n          next\n        }else{\n          x=predict(mod[[names(data[j])]], newdata=df_filled[i,])\n        }\n        if(t[j]==\"factor\"){\n          # if it is binary then it uses the most likely value\n          df_filled[i,j]=if_else(x&lt;0, levels(df_filled[,j])[1],levels(df_filled[,j])[2])\n        }else{\n          df_filled[i,j]=x\n        }\n      }\n    }\n    interim[[k]]=df_filled\n  }\n  #removes individual data from the output\n  for(i in remove_model_data){\n    mod[i][[i]]=NULL\n  }\n  return(list(\"data_imp\"=df_filled, \"mod\"=mod, \"init\"=init))\n}\n\n\ncols_to_na=c(\"fev1_bl\", \"smoking_bl\", \"eos_bl\")\nset.seed(2)\ndata1=study_data$EFFECT$ad %&gt;%\n  mutate(across(all_of(cols_to_na), ~ {\n    n &lt;- length(.x)\n    na_indices &lt;- sample(n, size = floor(0.2 * n))\n    .x[na_indices] &lt;- NA\n    .x\n  })) \ndata1$train=as.logical(rbinom(nrow(data1),1, 0.8))\n\nunpack(model_breakdown(model))\n\n###\n\ndata=data1%&gt;% filter(train) %&gt;% get_all_vars(model, data=.) %&gt;% dplyr::select(-all_of(mod.lhs), -trt_dur)\nimp_mod=regression_imp(data)\n\nhead(data)\n\n  arm_ipd eos_bl age_imp exac_bl sex smoking_bl fev1_bl\n1     ICS    0.2      55       1   M     Former    0.76\n2     ICS    0.0      55       1   M     Former    1.05\n3     ICS    0.1      65       1   M       &lt;NA&gt;    1.33\n4 Control    0.1      75       1   M    Current    0.80\n5     ICS    0.3      65       1   M     Former    1.03\n6     ICS    0.4      55       1   M    Current    1.29\n\nhead(imp_mod$data_imp)\n\n  arm_ipd eos_bl age_imp exac_bl sex smoking_bl fev1_bl\n1     ICS    0.2      55       1   M     Former    0.76\n2     ICS    0.0      55       1   M     Former    1.05\n3     ICS    0.1      65       1   M     Former    1.33\n4 Control    0.1      75       1   M    Current    0.80\n5     ICS    0.3      65       1   M     Former    1.03\n6     ICS    0.4      55       1   M    Current    1.29",
    "crumbs": [
      "Regression Imputation"
    ]
  },
  {
    "objectID": "ri.html#on-the-fly",
    "href": "ri.html#on-the-fly",
    "title": "Regression Imputation",
    "section": "On the fly",
    "text": "On the fly\n\nlibrary(tidyverse)\n\n\nregression_imp_on_the_fly=function(imp_mod,newdata, init=imp_mod[[\"init\"]], iter=10){\n  \n  #getting the mean/mode for each column to initialise the data\n  \n  \n  calculate_summary &lt;- function(col) {\n    if (is.numeric(col)) {\n      mean(col, na.rm = TRUE)\n    } else if (is.factor(col)) {\n      mode_val &lt;- levels(col)[which.max(tabulate(col))]\n      factor(mode_val, levels = levels(col))  # preserve factor structure\n    } else {\n      NA\n    }\n  }\n  \n  #only it is told to reinitialize the data\n  if(is.null(init)){\n    init &lt;- newdata %&gt;%\n      summarise(across(everything(), calculate_summary))\n  }\n  \n  \n  # filling the data in\n  df_filled &lt;- newdata %&gt;%\n    mutate(across(everything(), ~ coalesce(.x, init[[cur_column()]])))\n  \n  \n  na_data=newdata %&gt;% mutate(across(everything(), ~ ifelse(is.na(.x), 0, 1)))\n  rs=rowSums(na_data)\n  \n  class2=function(x)\n  {\n    return(class(x)[1])\n  }\n  \n  t=sapply(df_filled, class2)\n  \n  mod=imp_mod[[\"mod\"]]\n  \n  #a reapet for each iteration\n  for(k in 1:iter){\n    for(i in 1:dim(df_filled)[1]){\n      # cat(crayon::yellow(paste0(i, \"\\n\")))\n      for(j in 1:dim(df_filled)[2]){\n        # cat(crayon::blue(paste0(j, \"\\n\")))\n        if(na_data[i,j]==1){\n          next\n        }else{\n          x=predict(mod[[names(newdata[j])]], newdata=df_filled[i,])\n        }\n        if(t[j] %in% c(\"factor\", \"logical\")){\n          df_filled[i,j]=if_else(x&lt;0, levels(df_filled[,j])[1],levels(df_filled[,j])[2])\n        }else{\n          df_filled[i,j]=x\n        }\n        \n        \n      }\n    }\n  }\n  return(df_filled)\n}\n\n\n\n  arm_ipd eos_bl age_imp exac_bl sex smoking_bl fev1_bl\n1     ICS    0.4      75       2   M    Current    0.78\n2     ICS    0.2      75       1   M     Former    1.38\n3 Control    0.5      65       1   M       &lt;NA&gt;    1.00\n4     ICS    0.3      65       1   F    Current    0.71\n5 Control    0.4      65       1   M       &lt;NA&gt;      NA\n6     ICS     NA      55       2   M       &lt;NA&gt;    0.53\n\n\n  arm_ipd    eos_bl age_imp exac_bl sex smoking_bl  fev1_bl\n1     ICS 0.4000000      75       2   M    Current 0.780000\n2     ICS 0.2000000      75       1   M     Former 1.380000\n3 Control 0.5000000      65       1   M     Former 1.000000\n4     ICS 0.3000000      65       1   F    Current 0.710000\n5 Control 0.4000000      65       1   M     Former 1.114985\n6     ICS 0.2256478      55       2   M    Current 0.530000\n\n\n\nReferences\n\n\n1. Sisk R, Sperrin M, Peek N, Smeden M van, Martin GP. Imputation and missing indicators for handling missing data in the development and deployment of clinical prediction models: A simulation study. Statistical Methods in Medical Research. 2023;32(8):1461-1477. doi:10.1177/09622802231165001\n\n\n2. Van Buuren S, Groothuis-Oudshoorn K. mice: Multivariate Imputation by Chained Equations. doi:10.32614/CRAN.package.mice",
    "crumbs": [
      "Regression Imputation"
    ]
  },
  {
    "objectID": "splines.html",
    "href": "splines.html",
    "title": "Splines",
    "section": "",
    "text": "Splines give the opportunity to model non-linear interactions\nWe know there is a trt-cov interaction between ICS and Eos modeled through 2 stage MA on the interaction term, we wish to explore whether there is a non-linear trend.\nI started by testing Impact and Dransfield 2 (biggest studies with eos) with various knots and settled on 2 then worked through all of the other studies with EOS.\n\nAs a first test, used aov with a linear interaction and a spline term to see if there was a benefit to using splines over linear interaction\n\nRiley ch7 p1911\nSuggests using mv meta\nFrom initial prodding, severe exacs and pneumonia have too few events to be stable.",
    "crumbs": [
      "Splines"
    ]
  },
  {
    "objectID": "splines.html#mvma-on-spline-terms",
    "href": "splines.html#mvma-on-spline-terms",
    "title": "Splines",
    "section": "MVMA on spline terms",
    "text": "MVMA on spline terms\n\nCode\n\nlibrary(tidyverse)\nlibrary(crayon)\nlibrary(systemfit)\nlibrary(MASS)\nlibrary(boot)\nlibrary(metafor)\nlibrary(mvmeta)\nlibrary(splines)\n\nload(\"data/study_data.RDa\")\nsource(\"R/functions.R\")\n\n# This has all been copied out of vivli using chatgpt to transcribe screengrabs.\nspline_bs = function(data, indices, covar) {\n  #we only use eos&lt;=0.6 (still more than 95% of observations)\n  trial = data[indices,] %&gt;% filter(eos_bl &lt;= 0.6)\n  \n  formula = as.formula(paste0(\"exac_modsev_n ~ arm_ipd * ns(eos_bl, knots = c(0.1, 0.25)) + \", paste(covar, collapse = \"+\"),\"+ offset(trt_dur)\"))\n  #Note arm*spline(eos) gives the same as arm+spline(eos)+spline(arm*eos)\n  \n  reg1 = glm.nb(formula, data = trial)\n  out = c(tail(reg1$coefficients, 3))\n  \n  return(out)\n}\n\na = Sys.time()\nset.seed(2)\nboot_results = list()\n\nfor (i in 1:nrow(study_data$length)) {\n  R = 1000\n  study = study_data$length$study[i]\n  \n  #skip the trials with missing eos\n  if (study_data[[i]][[\"missing_eos\"]]) { \n    next \n  }\n  \n  cat(paste0(study, \"\\n\"))\n  \n  #and catch any errors so it doesn't break\n  tryCatch({\n    boot_results[[study]] = boot(\n      data = study_data[[study]][[\"ad\"]],\n      statistic = spline_bs,\n      R = R,\n      covar = study_data[[study]][[\"covar\"]]\n    )\n  },\n  error = function(e) {\n    cat(red(\"Error \\n\"))\n  })\n}\n\nb = Sys.time()\ndifftime(b, a, units = \"mins\")\n\nsave(boot_results, file = \"data/splines/boot.RDa\")\n\n\n#Using RR's code from the IPDMA course\nmvmeta = tribble(~\"study\", ~\"spline\", ~\"yi\", ~\"v1i\", ~\"v2i\", ~\"v3i\")\n\nfor (i in 1:length(boot_results)) {\n  study = names(boot_results)[i]\n  cat(paste0(study, \"\\n\"))\n  \n  x = data.frame(\n    \"study\" = rep(study, 3),\n    \"outcome\" = c(\"spline1_0_0.1\", \"spline2_0.1_0.25\", \"spline3_0.25_0.6\"),\n    \"yi\" = boot_results[[study]][[\"t0\"]]\n  )\n  \n  y = as.data.frame(cov(boot_results[[study]][[\"t\"]])) %&gt;%\n    rename(v1i = V1, v2i = V2, v3i = V3)\n  \n  mvmeta = mvmeta %&gt;%\n    rbind.data.frame(cbind.data.frame(x, y))\n}\n\nmvmeta2_vivli = mvmeta %&gt;% merge(study_data$length, by = \"study\")\nsave(mvmeta2_vivli, file = \"results/splines/bootstrap.RDA\")\n\nv = bldiag(lapply(split(mvmeta[, c(\"v1i\", \"v2i\", \"v3i\")], mvmeta$study), as.matrix))\n\nbiv.full.part = rma.mv(\n  yi, V = v, mods = ~ outcome - 1, \n  random = ~ outcome | study, struct = \"UN\", \n  data = mvmeta, method = \"REML\"\n)\n\nbiv.full.part %&gt;% summary()\n\nHad a play with the studies that use EOS\n\ninterpretation of mvmeta (set with splines at 0.1, 0.25 and then capped at 0.6).\n\nIt does seem that the spline is associative. I made two models, one with arm*spline(eos) and the other with arm+spline(eos)+spline(arm*eos) and got basically the same results.",
    "crumbs": [
      "Splines"
    ]
  },
  {
    "objectID": "splines.html#ma-on-the-marginal-effects",
    "href": "splines.html#ma-on-the-marginal-effects",
    "title": "Splines",
    "section": "MA on the marginal effects",
    "text": "MA on the marginal effects\nThe next idea was to examine whether there is a benefit to using splines.\n\nI took the spline model for each of the studies and boostrapped the treatment efffect at each eos value\nAfter doing that I used the BS mean as BS error to aggregate using a bog standard meta-analysis at each value to get the marginal effect over all studies.\nI then did the same for the linear model\n\nIn the main paper I have used a closed solution to get the marginal effect but for consistency here I used a bootstrap.\n\n\n\nHere is what I get. Different but not loads.\n\nReferences\n\n\n1. Riley RD, Tierney JF, Stewart LA. Individual Participant Data Meta-Analysis. A Handbook for Healthcare Research. Wiley; 2021.",
    "crumbs": [
      "Splines"
    ]
  },
  {
    "objectID": "submodels.html",
    "href": "submodels.html",
    "title": "Submodels",
    "section": "",
    "text": "submodels function\nThis is the main function in the submodels family.\n\nlibrary(tidyverse)\n\n\n#' @data the training data as a data frame\n#' @model the formula of the model as a formula or coercible to formula\n#' @model_fn the function of the model, currently, we know that lm glm, amd MASS::glm.nb work\n#' @submodel_type a choice between psm and ccsm\n#' @force_variables a vector of strings with varaibles that have to be in the model and drops any obs that have a missing force_variable\n#' @remove_model_data vector of things that need to be removed from the model data because of vivli\n#' @threshold_multiplier sets the threshold for how small the sample can be, default is 2 the total threshold is multiplier times number of variables\n#' @... arguments passed as necessary\n\nsubmodels&lt;- function(data, model, model_fn,submodel_type=c(\"psm\", \"ccsm\"), force_variables=c(),threshold_multiplier=2,remove_model_data=c(\"model\", \"y\", \"fitted\"), ...){\n  \n  #house keeping\n  submodel_type=match.arg(submodel_type,c(\"psm\", \"ccsm\")) #picks the first of submodels\n  if(!submodel_type %in% c(\"psm\", \"ccsm\")){\n    stop(\"psm or ccsm required\")\n  }\n  \n  # breakdown the model see helper functions\n  unpack(model_breakdown(model))\n  \n  model=as.formula(model) #coerces the model formula into a formula class object\n  mod.data&lt;- get_all_vars(model, data=data) %&gt;%\n    tidyr::drop_na(all_of(mod.lhs)) %&gt;%\n    tidyr::drop_na(all_of(force_variables))\n  \n  model_names=names(mod.data)\n  \n  sdata &lt;- mod.data[,-1] #remove the outcome \n  var_names=names(sdata) \n  unpack(missingness_pattern(sdata)) #gets the missingness patterns\n  \n  all.patterns0=expand.grid(rep(list(0:1),ncol(sdata))) \n  \n  names(all.patterns0)=var_names #makes every combination of missingness\n  \n  #stops the computing of models that would have dropped the force variables.\n  remove=intersect(var_names, force_variables)\n  all.patterns1=all.patterns0[rowSums(as.matrix(all.patterns0[,remove]==1))==0,]\n  all.patterns &lt;- factor(apply(all.patterns1,1,function(z) paste(z,collapse=\"\")))\n  obs.patterns &lt;- unique(tmp.pattern)\n  \n  # add the empty patterns into the list of things to do\n  if(length(setdiff(all.patterns,obs.patterns)) == 0){\n    empty.patterns = NULL\n  } else {\n    empty.patterns &lt;- data.frame(mp = factor(setdiff(all.patterns,obs.patterns)), n=0)\n  } \n  mp.info &lt;- rbind(mp.info,empty.patterns)\n  \n  \n  \n  # sets the threshold\n  threshold &lt;- (length(mod.rhs)+length(mod.rhs.interaction))*threshold_multiplier\n  \n  # sets whether the pattern uses a ccs or pms\n  mp.info$use.psm &lt;- (as.numeric(mp.info$n)&gt;=threshold)*1\n  \n  if(mp.info$use.psm[1]==0){\n    stop(\"Not enough data for the full model\")\n  }\n  \n  reg.out &lt;- vector('list', length(all.patterns))\n  names(reg.out) &lt;- mp.info$mp\n  \n  cols=names(mod.data)[names(mod.data)!=mod.lhs]\n  \n  for(i in seq(nrow(mp.info))) {\n    col.keep  &lt;- which(strsplit(mp.info$mp[i],'')[[1]]=='0')\n    \n    if(length(col.keep)==0){\n      new.mod &lt;- paste(mod.lhs,1,sep='~')\n    } else {\n      \n      vars_to_keep=cols[col.keep]\n      \n      new.mod=remove_missing_vars(model, cols, vars_to_keep)\n    }\n    \n    # makes sure that the right model is used so it will always use the complete case data if ccsm is chosen and then use ccsm if there is insufficient data points.\n    if(mp.info$use.psm[i]==1&submodel_type==\"psm\"){\n      \n      reg.out[[i]] &lt;- list(pattern=vars_to_keep,\n                         mp=mp.info$mp[i],\n                         mod=model_fn(formula=new.mod,data=mod.data[tmp.info[[i]],]))\n    }else{\n      \n      reg.out[[i]] &lt;- list(pattern = vars_to_keep,\n                         mp=mp.info$mp[i],\n                         mod=model_fn(formula=new.mod,data=mod.data))\n      \n    }\n    #this is a fix for vivli\n    for(j in remove_model_data){\n      reg.out[[i]][[\"mod\"]][[j]]=NULL\n    }\n  }\n  reg.out[[\"meta\"]][[\"model\"]]=model\n  reg.out[[\"meta\"]][[\"vars\"]]=var_names\n  reg.out[[\"meta\"]][[\"force_variables\"]]=force_variables\n  reg.out[[\"meta\"]][[\"mp.info\"]]=mp.info\n  reg.out[[\"meta\"]][[\"all.patterns\"]]=all.patterns\n  reg.out[[\"meta\"]][[\"submodel_type\"]]=submodel_type\n  reg.out[[\"meta\"]][[\"threshold\"]]=threshold\n  \n  return(reg.out)\n}\n\nstripped_model=function(submodel.object){\n  for(i in 1:length(submodel.object[[\"meta\"]][[\"all.patterns\"]])){\n   strip = list(\n        coefficients = submodel.object[[i]][[\"mod\"]]$coefficients,\n        terms = submodel.object[[i]][[\"mod\"]]$terms,\n        xlevels = submodel.object[[i]][[\"mod\"]]$xlevels,\n        family = submodel.object[[i]][[\"mod\"]]$family\n      )\n  \n  submodel.object[[i]][[\"mod\"]]=strip\n  }\n  return(submodel.object)\n}\n\n\nBasic premise of the function\n\nHousekeeping and sanitizing inputs\nGetting the missingness patterns (see Helper functions)\nStops the computing of models that would have dropped the force variables.\nSet the threshold (uses the number of variables in the model)\nLoops through all of the patterns and builds the models, which data is used depends on whether there is enough data.\n\nTODO: Examples\n\n\nExample: EFFECT\nNote: some missingness added for good measure and 80/20 test train ratio\n\nmodel=exac_modsev_n ~ arm_ipd*eos_bl+age_imp+exac_bl+sex+smoking_bl+fev1_bl+offset(trt_dur)\nsubmodels.object=submodels(data %&gt;% filter(train), model, MASS::glm.nb,force_variables=\"trt_dur\", contrasts=NULL, remove_model_data = c())\n\n#example\nsubmodels.object[1]\n\n$`00000000`\n$`00000000`$pattern\n[1] \"arm_ipd\"    \"eos_bl\"     \"age_imp\"    \"exac_bl\"    \"sex\"       \n[6] \"smoking_bl\" \"fev1_bl\"    \"trt_dur\"   \n\n$`00000000`$mp\n[1] \"00000000\"\n\n$`00000000`$mod\n\nCall:  model_fn(formula = new.mod, data = mod.data[tmp.info[[i]], ], \n    init.theta = 2.224975191, link = log)\n\nCoefficients:\n      (Intercept)         arm_ipdICS             eos_bl            age_imp  \n          0.03938           -0.58392            0.14000           -0.00564  \n          exac_bl               sexM  smoking_blCurrent            fev1_bl  \n          0.14616           -0.21439            0.09420           -0.90601  \narm_ipdICS:eos_bl  \n          0.94040  \n\nDegrees of Freedom: 715 Total (i.e. Null);  707 Residual\nNull Deviance:      748.3 \nResidual Deviance: 685.3    AIC: 1540\n\nsubmodels.object$meta$vars\n\n[1] \"arm_ipd\"    \"eos_bl\"     \"age_imp\"    \"exac_bl\"    \"sex\"       \n[6] \"smoking_bl\" \"fev1_bl\"    \"trt_dur\"   \n\nhead(submodels.object$meta$mp.info)\n\n        mp   n use.psm\n1 00000000 716       1\n2 00000010 191       1\n3 00000100 181       1\n4 00000110  39       1\n5 01000000 175       1\n6 01000010  43       1\n\nsubmodels.object$meta$threshold\n\n[1] 18\n\n\nTo do: think about classes of the object so that you can just use predict() and print() and it just knows what to do.\n\n\n\npredict.submodels\n\n#' @prediction.data the data used for testing\n#' @submodels.object from submodels\n#' @se.fit if the SE of prediction is to be used.\n#' @retain_lhs if the true outcome variable is to be be kept in the output.\n#' @include_mp if the mssingness pattern is to be included in the output data frame. \n#' @... arguments passed as necessary\n\npredict.submodels &lt;- function(newdata, submodels.object,se.fit=TRUE,retain_lhs=FALSE,include_mp=FALSE, ...){\n  \n  #break down the model as passsed to the first argument.\n  unpack(model_breakdown(submodels.object[[\"meta\"]][[\"model\"]]))\n  \n  #keeping the correct bits of data.\n  mod.data&lt;-newdata %&gt;% dplyr::select(any_of(c(mod.lhs, submodels.object[[\"meta\"]][[\"vars\"]]))) %&gt;% \n    tidyr::drop_na(all_of(submodels.object[[\"meta\"]][[\"force_variables\"]]))\n  \n  #its useful to have a copy\n  sdata&lt;- mod.data\n  \n  #adding missing cols\n  missing_vars=submodels.object[[\"meta\"]][[\"vars\"]][!submodels.object[[\"meta\"]][[\"vars\"]] %in% names(sdata)]\n  \n  for(i in missing_vars){\n    sdata[,i] &lt;- NA\n  }\n  \n  # getting the missingness patterns and setting up the data ready.\n  unpack(missingness_pattern(sdata %&gt;% dplyr::select(-any_of(mod.lhs))))\n  mp.info=submodels.object[[\"meta\"]][[\"mp.info\"]]# %&gt;% filter(mp %in% mp.info$mp)\n  \n  pred.out=sdata[0,]\n  pred.out$fit=numeric(0)\n  if(se.fit){\n    pred.out$se.fit=numeric(0)\n  }\n  if(include_mp){\n    pred.out$mp=character(0)\n  }\n  \n  # predicting for each missing pattern\n  for(i in 1:nrow(mp.info)){\n    newdata_mp=sdata[tmp.info[[mp.info$mp[i]]],]\n    if(nrow(newdata_mp)==0){next}\n    pred=predict(submodels.object[[i]][[\"mod\"]], newdata=newdata_mp, se.fit=se.fit,...)\n    if(se.fit){\n      newdata_mp$fit=pred$fit \n      newdata_mp$se.fit=pred$se.fit\n    }else{\n      newdata_mp$fit=pred.out\n    }\n    if(include_mp){\n      newdata_mp$mp=mp.info$mp[i]\n    }\n    pred.out=pred.out %&gt;% rbind(newdata_mp)\n  }\n  if(!retain_lhs){\n    pred.out=pred.out %&gt;% dplyr::select(-any_of(mod.lhs))\n  }\n  \n  return(pred.out)\n}\n\n\nVarious bits of house keeping getting the model ready (maybe the model_breakdown function can be removed and inheritted from the main function)\n\n\nnewdata=data %&gt;% filter(!train)\ntest=predict.submodels(newdata=newdata, submodels.object = submodels.object, se.fit=T,retain_lhs = T,include_mp=T, type='response')\n\nhead(test %&gt;% \n       mutate(rn=row_number(), .by=\"mp\") %&gt;% \n       arrange(rn) %&gt;% \n       dplyr::select(-rn))\n\n  exac_modsev_n arm_ipd eos_bl age_imp exac_bl sex smoking_bl fev1_bl   trt_dur\n1             4     ICS    0.4      75       2   M    Current    0.78 0.5147159\n2             0 Control    0.6      75       1   M    Current      NA 0.2847365\n3             1 Control    0.5      65       1   M       &lt;NA&gt;    1.00 0.2518823\n4             2 Control    0.4      65       1   M       &lt;NA&gt;      NA 1.0403833\n5             0     ICS     NA      75       1   M    Current    1.26 1.0130048\n6             0 Control     NA      65       1   M    Current      NA 1.0047912\n        fit     se.fit       mp\n1 0.5739488 0.08942161 00000000\n2 1.0573189 0.74805828 00000010\n3 0.2220316 0.08043407 00000100\n4 2.4833401 1.60324752 00000110\n5 0.5319815 0.16172669 01000000\n6 0.3797390 0.18877008 01000010",
    "crumbs": [
      "R Code",
      "Submodels"
    ]
  }
]